<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="noarchive">
  <title>Time-to-Move: Training-Free Motion Controlled Video Generation via Dual-Clock Denoising</title>
    <link rel="stylesheet" href="style_new.css">
    <link rel="stylesheet" href="style_new.css">
<style>.authors, .authors a, .authors sup { color:#fff; }</style>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@300;400;600;700&display=swap" rel="stylesheet">
</head>
<body>
  <div class="page-container">
    
    <!-- Title Section -->
    <header class="paper-header">
      <h1 class="paper-title">Time-to-Move: Training-Free Motion Controlled Video Generation via Dual-Clock Denoising</h1>
      
      <!-- Authors -->
      <div class="authors">
        <span class="author"><a href="https://www.linkedin.com/in/assaf-singer/">Assaf Singer</a><sup>†, 1</sup></span>
        <span class="author"><a href="https://rotsteinnoam.github.io/">Noam Rotstein</a><sup>†, 1</sup></span>
        <span class="author"><a href="https://www.linkedin.com/in/amir-mann-a890bb276/">Amir Mann</a><sup>1</sup></span>
        <span class="author"><a href="https://ron.cs.technion.ac.il/">Ron Kimmel</a><sup>1</sup></span>
        <span class="author"><a href="https://orlitany.github.io/">Or Litany</a><sup>1, 2</sup></span>
      </div>

    <!-- Institutions -->
    <div class="affiliations">
      <span class="affiliation"><sup>1</sup>Technion - Israel Institute of Technology</span>
      <span class="affiliation"><sup>2</sup>NVIDIA</span>        
    </div>
    <p class="equal-contrib" style="margin-top:6px;font-size:1rem;color:#ffffff;">
      <sup>†</sup> Equal contribution
    </p>

      <!-- Links -->
      <div class="paper-links">
      <!-- Paper (PDF) -->
      <a href="assets/ttm_paper.pdf" class="paper-btn">
        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" aria-hidden="true">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
        </svg>
        Paper (PDF)
      </a>

      <!-- arXiv -->
      <a href="https://arxiv.org/abs/2501.01234" class="paper-btn" target="_blank" rel="noopener">
        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" aria-hidden="true">
          <path d="M18 13v6a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
          <polyline points="15 3 21 3 21 9"></polyline>
          <line x1="10" y1="14" x2="21" y2="3"></line>
        </svg>
        arXiv
      </a>
        <a href="https://github.com/RotsteinNoam/time-to-move" class="paper-btn">
          <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
          </svg>
          Code
        </a>
        <a href="supplementary.html" class="paper-btn">
          <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <rect x="3" y="3" width="18" height="18" rx="2" ry="2"></rect>
            <line x1="9" y1="3" x2="9" y2="21"></line>
          </svg>
          Supplementary
        </a>
      </div>
    </header>

    <!-- Teaser Video -->
    <section class="teaser-section">
      <!-- <h2>Teaser</h2> -->
      <div class="teaser-video-container">
        <video class="teaser-video" autoplay loop muted playsinline controls>
          <source src="assets/teaser_placeholder.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <!-- <p class="video-caption">Teaser video showcasing our method for training-free motion-controlled video generation.</p> -->
      </div>
    </section>

    <!-- Abstract -->
    <section class="abstract-section">
    <h2>Abstract</h2>
    <p class="abstract-text" style="line-height:1.28;margin:0;">
      We introduce <strong>Time-to-Move (TTM)</strong>, a <strong>training-free</strong>, plug-and-play framework that adds precise motion control to existing video diffusion models.
      While many prior methods require costly, model-specific fine-tuning, TTM avoids this.
      Our key insight is to use <strong>crude reference animations</strong>—such as “cut-and-drag” or depth-based reprojection—as coarse motion cues.
      Inspired by SDEdit, we adapt its mechanism to the video domain. 
      First, we use <strong>image conditioning</strong> with image-to-video models to preserve appearance, and second, we introduce <strong>dual-clock denoising</strong>, a novel region-dependent strategy.
      This technique enforces stronger alignment in motion-specified regions while allowing more natural dynamics and flexibility elsewhere.
      The approach is compatible with any backbone model.
      Moreover, compared to previous motion control methods, TTM enables joint control over both <strong>motion and appearance</strong>.
      Experiments demonstrate that it achieves comparable or superior performance to training-based baselines in both realism and motion fidelity.
    </p>
    </section>

    <!-- Method Overview -->
    <section class="method-section">
      <h2>Method Overview</h2>
      <div class="method-figure">
        <img src="assets/method_figure_v9.png" alt="Method Overview" class="method-img">
      </div>
      
      <div class="method-description" style="line-height:1.28;margin:0;">
        <p>
        Time-to-Move (TTM) takes an input image and a user-specified motion, then automatically builds <strong>(i)</strong> a coarse warped reference video and <strong>(ii)</strong> a mask marking the controlled region.
        The image-to-video diffusion model is conditioned on the clean input image and initialized from a noisy version of the warped reference, anchoring appearance while injecting the intended motion.
        During sampling, dual-clock denoising is applied: lower noise inside the mask to enforce the commanded motion, higher noise elsewhere to enable it to evolve naturally.
        The result is a realistic video that preserves input details and faithfully follows the motion without extra training or architectural changes.
        </p>
      </div>
      
      </section>

    <!-- Dual-Clock Denoising -->
    <section class="dual-clock-section">
      <h2>Dual-Clock Denoising</h2>
      <div class="dual-clock-figure">
        <div class="dual-clock-video-container">
          <video class="dual-clock-video" autoplay loop muted playsinline controls>
            <source src="assets/dual_clock2.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </div>
      <div class="dual-clock-description" style="line-height:1.28;margin:0;">
        <!-- <p>
          The key innovation of our method is the dual-clock denoising mechanism. Traditional video diffusion models use a single 
          denoising schedule for all frames. In contrast, we introduce two separate "clocks" that denoise at different rates: 
          a fast clock for content generation and a slow clock for motion preservation. This allows us to maintain temporal consistency 
          while generating high-quality visual details.
        </p> -->
        <p>
        We present a region-dependent denoising strategy.
        Previous methods have limitations: SDEdit either suppresses dynamics in unmasked regions (at high noise levels) or drifts from the prescribed motion (at low levels). RePaint, on the other hand, enforces motion without denoising, but this introduces artifacts.
        We propose a dual-clock method where masked regions follow the intended motion with strong fidelity, while the rest of the scene denoises more freely.
        This flexible approach yields realistic dynamics without artifacts.
      </p>
      </div>
    </section>

    <!-- User-Specified Object Control (plays 81 frames @ 24 fps) -->
    <section id="UserObjectControl" class="results-section">
      <h2>Object Motion Control</h2>
      <p class="section-description" style="line-height:1.28;margin:0;">
        Examples of user-specified object control. The user selects one or more regions of interest in an image using a mask and defines their trajectories. 
        The masked regions are then dragged across all frames to produce a coarse, warped version of the intended object animation. 
        Finally, <strong>TTM</strong>, integrated with the <strong>Wan&nbsp;2.2</strong> video model, generates a high-quality, dynamic video that accurately reflects the user’s intent.
      </p>
      <div class="video-grid-2col">
        <div class="video-item">
          <video src="UserObjectControl/monkeyjumpingonthebed_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserObjectControl/jumping_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserObjectControl/gardening_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectControl/surfing_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectControl/owl_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectControl/girljuggling_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectControl/timesquaresv5_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectControl/Vines_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectControl/cuttingcucumber_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectControl/carhighway_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectControl/Rhino_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectControl/Turtle_concat2.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
      </div>
    </section>


    <!-- User-Specified Camera Control (plays 81 frames @ 16 fps) -->
    <section id="UserCameraControl" class="results-section">
      <h2>Camera Motion Control</h2>
      <p class="section-description" style="line-height:1.28;margin:0;"></p>
        Examples of user-specified camera control from a single image. From any image, we estimate its depth and then,
        based on a user-defined camera motion, we generate a warped video of the original frame as seen from each new viewpoint.
        We fill any resulting holes with the nearest neighbor color, which creates a rough initial video of the desired camera movement.
        We then use TTM with <a href="https://github.com/Wan-Video/Wan2.2">Wan 2.2</a> video model to
        generate a realistic video that accurately follows the specified camera motion.
      </p>
      <div class="video-grid-2col">
        <div class="video-item">
          <video src="UserCameraControl/bridge1_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserCameraControl/concertstage_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserCameraControl/volcano_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserCameraControl/Bridge2_concat_3.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <!-- <div class="video-item">
            <video src="UserCameraControl/concertcrowd_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div> -->
        <div class="video-item">
            <video src="UserCameraControl/riverup_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserCameraControl/volcanotitan_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
      </div>
    </section>

    <!-- User-Specified Camera Control (plays 81 frames @ 24 fps) -->
    <section id="UserObjectAppearanceControl" class="results-section">
      <h2>Motion and Appearance Control</h2>
      <p class="section-description">
        Examples of user-specified object and appearance control from a single image.
        Our method also allows for the insertion of new objects from outside the original image, as well as altering the appearance of a specific object by changing its color or shape.
        We generate a rough, warped version of the intended object animation along with the desired appearance changes.
        We then use TTM with <a href="https://github.com/Wan-Video/Wan2.2">Wan 2.2</a> video model to
        generate a the output video.
      </p>
      <div class="video-grid-2col">
        <div class="video-item">
            <video src="UserObjectAppearanceControl/TimeToMoveVideo_concat_4.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
          <video src="UserObjectAppearanceControl/cocktail2_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserObjectAppearanceControl/puttingonahat_concatenated_fixed.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserObjectAppearanceControl/ChameleonColor_concat.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserObjectAppearanceControl/Sunset_concat.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserObjectAppearanceControl/concat_motion_left_fps=24.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserObjectAppearanceControl/RaceCars_concat.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
        <div class="video-item">
            <video src="UserObjectAppearanceControl/ChameleonFade_concat.mp4" autoplay loop muted playsinline controls></video>
            <p class="video-label">Warped | Ours</p>
        </div>
      </div>
    </section>


    <!-- Qualitative Comparison - Object Control (plays 81 frames @ 24 fps)  -->
    <section class="comparison-section">
      <h2>Qualitative Comparison: Object Control</h2>
      <p class="section-description" style="line-height:1.28;margin:0;">
        Comparison of our method with state-of-the-art approaches on user-specified object control tasks. 
        All methods use the same base video model for fair comparison.
      </p>
      <!-- Videos - Hamburger, Snooker, Find Other -->
      <div class="comparison-grid">
        <div class="comparison-item">
          <video src="UserObjectControl_Comparison/Hamburger_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours (Wan 2.2) | Ours (CogVideoX) | GWTF</p>
        </div>
        <div class="comparison-item">
          <video src="UserObjectControl_Comparison/Snooker_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours (Wan 2.2) | Ours (CogVideoX) | GWTF</p>
        </div>
        <div class="comparison-item">
          <video src="UserObjectControl_Comparison/BillboardUnrolling_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours (Wan 2.2) | Ours (CogVideoX) | GWTF</p>
        </div>
        <div class="comparison-item">
          <video src="UserObjectControl_Comparison/CuttingCucumber_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours (Wan 2.2) | Ours (CogVideoX) | GWTF</p>
        </div>
        <div class="comparison-item">
          <video src="UserObjectControl_Comparison/Surfing_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours (Wan 2.2) | Ours (CogVideoX) | GWTF</p>
        </div>
        <div class="comparison-item">
          <video src="UserObjectControl_Comparison/CarHighway_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours (Wan 2.2) | Ours (CogVideoX) | GWTF</p>
        </div>
      </div>
    </section>

    <!-- Qualitative Comparison - Camera Control (plays 81 frames @ 16 fps) -->
    <section class="comparison-section">
      <h2>Qualitative Comparison: Camera Control</h2>
      <p class="section-description" style="line-height:1.28;margin:0;">
        Comparison of our method with state-of-the-art approaches on user-specified camera control tasks.
      </p>
      <div class="comparison-grid">
        <div class="comparison-item">
          <video src="UserCameraControl_Comparison/RiverOcean_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours (Wan 2.2) | Ours (CogVideoX) | GWTF</p>
        </div>
        <div class="comparison-item">
          <video src="UserCameraControl_Comparison/SpiderMan_concat.mp4" autoplay loop muted playsinline controls></video>
          <p class="video-label">Warped | Ours (Wan 2.2) | Ours (CogVideoX) | GWTF</p>
        </div>
      </div>
    </section>

    <!-- BibTeX -->
    <section class="bibtex-section">
      <h2>Citation</h2>
      <pre class="bibtex"><code>@article{yourname2025timetomove,
  title={Time-to-Move: Training-Free Motion Controlled Video Generation via Dual-Clock Denoising},
  author={Author Names},
  journal={Conference/Journal Name},
  year={2025}
}</code></pre>
    </section>

    <!-- Footer -->
    <footer class="page-footer">
      <p>© 2025 - Time-to-Move Project Page</p>
      <p><a href="supplementary.html">View Supplementary Materials</a></p>
    </footer>

  </div>
</body>
</html>
